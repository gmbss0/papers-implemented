{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06a7bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T14:35:13.549112Z",
     "start_time": "2022-08-23T14:34:57.909480Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # set according to available resources "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f3bb6",
   "metadata": {},
   "source": [
    "##  DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0673c352",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T09:12:29.634208Z",
     "start_time": "2022-08-23T09:12:29.611491Z"
    }
   },
   "source": [
    "### to be done by user...\n",
    "build datasets: might be image-captions, image-image... depending on encoders\n",
    "To make the code work, simply assign a tf-dataset to \"train_ds\" and optionally a validation set to \"val_ds\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7b1e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T14:35:46.047199Z",
     "start_time": "2022-08-23T14:35:45.193014Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = None\n",
    "val_ds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d0d698",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T12:42:40.585506Z",
     "start_time": "2022-08-22T12:42:40.463675Z"
    }
   },
   "source": [
    "### CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9101c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T14:35:46.333856Z",
     "start_time": "2022-08-23T14:35:46.129227Z"
    }
   },
   "outputs": [],
   "source": [
    "from helpers import helpers\n",
    "cfg = helpers.load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a7667",
   "metadata": {},
   "source": [
    "# BUILD MODELS\n",
    "VICReg is a general-purpose architecture that should allow multi-modal represenation learning. To test the multi-modal capabilities this VICReg consists of an image encoder (ResNet-like architecture) and a text encoder (Vanilla Transformer). Two MLPs are used for the expander models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26fea3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T14:35:48.970308Z",
     "start_time": "2022-08-23T14:35:48.843412Z"
    }
   },
   "outputs": [],
   "source": [
    "from models import models\n",
    "\n",
    "rep_dim = cfg.representation_dim  # dimension of encoder output\n",
    "emb_dim = cfg.embedding_dim  # dimension of expander output\n",
    "exp_layers = cfg.n_expander_layers\n",
    "# encoder specific configs\n",
    "encoder_1_cfg = cfg.encoder_1_config\n",
    "encoder_2_cfg = cfg.encoder_2_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd0882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T14:35:49.988543Z",
     "start_time": "2022-08-23T14:35:49.890374Z"
    }
   },
   "outputs": [],
   "source": [
    "# inputs -> based on specific datasets and modalities\n",
    "img_size = (256, 256)\n",
    "seq_len = 25\n",
    "vocab_size = 10_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f5412",
   "metadata": {},
   "source": [
    "### Encoder 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69045ec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T14:35:51.169382Z",
     "start_time": "2022-08-23T14:35:51.073322Z"
    }
   },
   "outputs": [],
   "source": [
    "# define input_shape -> should match encoder\n",
    "input_shape_1 = img_size + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f3dfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T14:35:52.405326Z",
     "start_time": "2022-08-23T14:35:51.729497Z"
    }
   },
   "outputs": [],
   "source": [
    "# build encoder 1 \n",
    "encoder_1 = models.build_ResNet(input_shape_1, blocks=encoder_1_cfg.n_channels, z_dim=rep_dim)\n",
    "# build expander 1\n",
    "expander_1 = models.build_expander(embedding_dim=emb_dim, expander_layers=exp_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967bd84c",
   "metadata": {},
   "source": [
    "### Encoder 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632eceb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T14:35:53.859479Z",
     "start_time": "2022-08-23T14:35:53.605023Z"
    }
   },
   "outputs": [],
   "source": [
    "# build encoder 2\n",
    "encoder_2 = models.TextEncoder(encoder_2_cfg.n_layers, seq_len, vocab_size, encoder_2_cfg.d_model,\n",
    "                               encoder_2_cfg.num_heads, encoder_2_cfg.mlp_dim, encoder_2_cfg.dropout)\n",
    "# build expander 2\n",
    "expander_2 = models.build_expander(embedding_dim=emb_dim, expander_layers=exp_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18634c",
   "metadata": {},
   "source": [
    "## VICReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd66c79c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T14:35:55.225694Z",
     "start_time": "2022-08-23T14:35:55.129632Z"
    }
   },
   "outputs": [],
   "source": [
    "V_loss, I_loss, C_loss = models.V_loss, models.I_loss, models.C_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fc5c12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T14:35:57.211359Z",
     "start_time": "2022-08-23T14:35:57.076268Z"
    }
   },
   "outputs": [],
   "source": [
    "# build and compile model\n",
    "params = {\"V_loss_weight\" : cfg.loss_weights.variance, \"I_loss_weight\" : cfg.loss_weights.invariance,\n",
    "          \"C_loss_weight\" : cfg.loss_weights.covariance}\n",
    "model = models.VICReg(encoder_1, encoder_2, expander_1, expander_2, params)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=cfg.learning_rate)\n",
    "model.compile(opt, V_loss, I_loss, C_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62682e35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T14:36:58.878399Z",
     "start_time": "2022-08-23T14:35:58.618134Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=cfg.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cca57f8",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Check that represenations do not collapse:\n",
    "1. informational collapse (all features identical)\n",
    "2. sample-wise collapse (identical representation for all samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c31b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
